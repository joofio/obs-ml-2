{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566064af-e67e-477a-bfb1-c45064886158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:29:51.782305Z",
     "iopub.status.busy": "2022-02-07T15:29:51.781665Z",
     "iopub.status.idle": "2022-02-07T15:29:53.733603Z",
     "shell.execute_reply": "2022-02-07T15:29:53.733310Z",
     "shell.execute_reply.started": "2022-02-07T15:29:51.782255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "import shap\n",
    "from shap import Explanation\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    LabelBinarizer,\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn import preprocessing\n",
    "from lightgbm import LGBMClassifier\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d59ad-a397-4b50-9fcd-e06f0ad62e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_option('deprecation.showPyplotGlobalUse', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68946936-86e2-4771-92e8-03ba0451aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_object(x):\n",
    "    return pd.DataFrame(x).astype(str)\n",
    "\n",
    "def to_number(x):\n",
    "    return pd.DataFrame(x).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d5e5aed-087a-49b2-b9c3-54c9ca7f62af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T15:32:33.737360Z",
     "iopub.status.busy": "2022-02-07T15:32:33.736593Z",
     "iopub.status.idle": "2022-02-07T15:32:33.751697Z",
     "shell.execute_reply": "2022-02-07T15:32:33.748811Z",
     "shell.execute_reply.started": "2022-02-07T15:32:33.737305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('feature_data_012.json') as json_file:\n",
    "    columns = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02a708e-2f96-4d31-a132-5f6fc6aa66d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-07T16:09:56.760068Z",
     "iopub.status.busy": "2022-02-07T16:09:56.757951Z",
     "iopub.status.idle": "2022-02-07T16:09:56.873442Z",
     "shell.execute_reply": "2022-02-07T16:09:56.872013Z",
     "shell.execute_reply.started": "2022-02-07T16:09:56.759738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col,values \u001b[38;5;129;01min\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpred_cols\u001b[49m\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[1;32m      3\u001b[0m     ncol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(col\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#options=[str(cols).replace(\"NULLIMP\",\"Unknown\") for cols in columns[col]]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_cols' is not defined"
     ]
    }
   ],
   "source": [
    "row={}\n",
    "pred_cols=[]\n",
    "for col,values in columns.items():\n",
    "    pred_cols.append(col)\n",
    "    ncol=\" \".join(col.split(\"_\"))\n",
    "    options=[str(cols).replace(\"nan\",\"Unknown\") for cols in values[1]]\n",
    "\n",
    "    if values[0] in[\"cat\",\"ord\"]:\n",
    "     #   print(\"cat\")\n",
    "    \n",
    "        row[col]=[st.sidebar.selectbox(ncol, options,key=col)]\n",
    "        \n",
    "    if values[0] in[\"int\"]:\n",
    "       # print(col)\n",
    "        #print(values[1][0])\n",
    "        row[col]=[st.sidebar.number_input(ncol,min_value=values[1][0],max_value=values[1][1],value=values[1][2],step=0.5,key=col)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8328f3-f946-4f29-9187-99b74eb1ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfrom_array_to_df_onehot(pl,nparray,onehot=True):\n",
    "    col_list_int = pl[\"preprocessor\"].transformers_[0][2] #changes col location\n",
    "    #print(col_list_int)\n",
    "    ordinal_col=pl[\"preprocessor\"].transformers[1][2]\n",
    "    original_col=pl[\"preprocessor\"].transformers[2][2]\n",
    "    col_list=col_list_int.copy()\n",
    "    col_list.extend(ordinal_col)\n",
    "    if onehot:\n",
    "        encoded_col=pl[\"preprocessor\"].transformers_[2][1].named_steps[\"OneHotEnconding\"].get_feature_names_out()\n",
    "    \n",
    "        #print(len(encoded_col))\n",
    "        new_enconded_list=[]\n",
    "        for idx,col in enumerate(original_col):\n",
    "            for n_col in encoded_col:\n",
    "            #print(idx,col)\n",
    "           # print(\"x\"+str(idx))\n",
    "                if \"x\"+str(idx)+\"_\" in n_col:\n",
    "                 #   print(col,n_col)\n",
    "                    new_enconded_list.append(col+\"_\"+n_col.split(\"_\")[-1])\n",
    "        \n",
    "        col_list.extend(new_enconded_list)\n",
    "    #    print(col_list)\n",
    "        #print(len(col_list))\n",
    "    else:\n",
    "        col_list.extend(original_col)\n",
    "\n",
    "    df1 = pd.DataFrame(nparray, columns=col_list)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d353dbc-6675-44d2-87a1-c9e735455905",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"\"\"Please select the options on the sidebar for the model to predict the delivery type. Click the button in the end of the sidebar to start prediction\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b470007-436f-484e-8c21-b27437cb4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model_lgbm_.sav'\n",
    "loaded_model = joblib.load(filename)\n",
    "filename = 'pipeline_012.sav'\n",
    "pipeline = joblib.load(filename)\n",
    "filename = 'label_encoder_012.sav'\n",
    "label_encoder = joblib.load(filename)\n",
    "filename = 'explainer_012.sav'\n",
    "explainer = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35857f5-6b38-4436-abcf-3fa144bf887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outcome(le,arr):\n",
    "    outcome_dict={}\n",
    "    for idx,class_ in enumerate(le.classes_):\n",
    "        outcome_dict[class_]=[str(round(arr[0][idx]*100,2)) +\" %\"]\n",
    "    return pd.DataFrame.from_dict(outcome_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17a6cb-5dbb-4948-b1c7-61f39378bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adddummy_variable(X,pl):\n",
    "    col_list_int = pl[\"preprocessor\"].transformers_[0][2] #changes col location\n",
    "    ordinal_col=pl[\"preprocessor\"].transformers[1][2]\n",
    "    original_col=pl[\"preprocessor\"].transformers[2][2]\n",
    "    for c in col_list_int:\n",
    "        if c not in X.columns:\n",
    "            X[c]=0\n",
    "    for idx,c in enumerate(original_col):\n",
    "\n",
    "        if c not in X.columns:\n",
    "            X[c]=pipeline[\"preprocessor\"].transformers_[2][1][2].categories_[idx][0]\n",
    "    for idx,c in enumerate(ordinal_col):\n",
    "        print(c)\n",
    "        if c not in X.columns:\n",
    "            X[c]=\"0\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68d994-e722-43a0-b4b5-cadf44c19919",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction=st.sidebar.button('Make Prediction')\n",
    "explaining=st.sidebar.button('Make Prediction with Shap Values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909f33c-6516-4144-a7e8-636bc87269d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamlit_predict(row):\n",
    "    df=pd.DataFrame.from_dict(row)\n",
    "    st.write('Predicting for')\n",
    "   # st.write(row)\n",
    "    st.dataframe(df)\n",
    "    X_=adddummy_variable(df.copy(),pipeline)\n",
    "    X_=X_.replace({'Unknown': 'nan'})\n",
    "\n",
    "   # st.dataframe(X_)\n",
    "    X=pipeline.transform(X_)\n",
    "   # st.write(\"ipeline\")\n",
    "    df1=transfrom_array_to_df_onehot(pipeline,X,onehot=False)\n",
    "   # st.dataframe(df1)\n",
    "    X_new=df1.loc[:,pred_cols]\n",
    "    pred=loaded_model.predict(X_new.values)\n",
    "    pred_proba=loaded_model.predict_proba(X_new.values)\n",
    "    st.markdown(\"### The prediction is:  \")\n",
    "    st.write(label_encoder.inverse_transform(pred)[0])\n",
    "    st.dataframe(create_outcome(label_encoder,pred_proba))\n",
    "    return df,X_new,pred,pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d25cb-ffcd-4fc7-a65d-dc547fc0d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_prediction:\n",
    "    streamlit_predict(row)\n",
    "\n",
    "if explaining:\n",
    "    df,X_new,pred,pred_proba=streamlit_predict(row)\n",
    "    print(df.shape,X_new.shape)\n",
    "    st.write('Explaining using SHAP values...')\n",
    "    shap_values = explainer.shap_values(X_new.values,check_additivity=False)\n",
    "    #Now we can plot relevant plots that will help us analyze the model.\n",
    "    st.subheader(\"Summary Plot\")\n",
    "    shap.summary_plot(shap_values, X_new.values, plot_type=\"bar\", class_names= label_encoder.classes_, feature_names = X_new.columns)\n",
    "    st.pyplot(bbox_inches='tight',dpi=300,pad_inches=0)\n",
    "    pl.clf()\n",
    "    st.subheader(\"Force Plot\")\n",
    "    shap.force_plot(explainer.expected_value[pred[0]], shap_values[pred[0]],df,matplotlib=True,show=False,figsize=(40,10))\n",
    "    st.pyplot(bbox_inches='tight',dpi=300,pad_inches=0)\n",
    "    pl.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c6027-f308-48a4-931a-4adf142f262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/sgoede/streamlit-boston-app/blob/master/boston_xgb_app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
